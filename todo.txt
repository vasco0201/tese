Next steps:

-> Registar o erro para cada horizonte de predição para os dados das auto estradas
-> Tenho de ver como é que a loss evolui para cada horizonte de predição 
-> Falta ver a evolução da loss para os dados das espiras
-> Continuar a fazer o plot para freeways!!!!
-> Ter um script para transformar os dados de uma espira em dados prontos para o arima *IMOPRTANTE*
-> tentar reproduzir os resultados do paper que diz que oarima não precisa de mtos dados e ir aumentando o conj de treino para ver se os resultados alteram
al
-> Falta continuar o plot da loss/epochs
-> Decobri empiricamente através do plot do fluxo do transito da autoestrada que há uma diferença CLARA no que diz respeito aos dias de semana e aos fins de semana
-> deveria identificar os 0 como missing values?
-> tentar melhorar performance utilizando early stopping
-> Experimentar com dados de dias homologos (semana passada e etc)
-> criar uma lista dos ficheiros gerados para poder fazer um make_clean porque já tenho 300000 ficheiros

Already Done
-> testar as resdes para 30,45 e 60 minutos feito, só falta registar resultados -> Feito tá no docs
-> Atualmente o modelo está overfitted porque val loss >> loss -> solved with weight regularization and less epochs
-> ver a média dos pesos para ver se há algum que seja absurdo ->
-> try L1+L2 regularization
-> Fazer um log para começar a registar resultados e tirar conclusoes
-> Preciso de estudar mais a fundo os diferentes optimizers para ver qual o melhor - Irrelevante o adam é melhor
-> testar com espiras confluentes para ver se melhora os restultados (já está no notebook agora é preciso por em codigo) - O caso testado não demonstrou melhorias
-> Correr isto para todas as espiras e ver se os resultados sao semelhantes - In progress
   -> Se calhar não devia separar o dataset aleatoreamente né (:
-> incorporar o dataset completo (os 3 que temos atualmente)
-> Descobrir os melhores parametros para a rede automaticamente - n vale a pena


Questions:
	-> MAE é menor mas MSE aumenta?????????
	-> Val loss ligeiramente menor do que a loss
	-> SQMAPE sklearn



Freeway data (provided by Jianhua Guo)
Arima -> Running
	  -> Model params for the first freeway : (5,0,0)(0, 1, 0)[96]
	  -> Split the set in training and testing sets
	  -> Come up with a way to plot mean mape for each time of day 
NN -> 11% mape, maybe have to try different parameters (but theres clearly an improvement vs the loop sensor data)
   -> Sudden large increase in the error
   ->


Missing values: 
	-> imputation using average of the last hour of traffic flow  
	-> Change it to average of before and after  the missing value


Coisas interessantes para falar:

Smoothing :
	Tentei com Z-Score e agora estou a utilizar a média + 2* std dev para detectar outliers e faço a media dos valores adjacentes para imputar

Other useful info:
merge multiple files and delete duplicate lines:  awk '!seen[$0]++' file1.txt file2.txt file3.txt > out20.txt 
