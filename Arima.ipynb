{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "1901-01-01    266.0\n",
      "1901-02-01    145.9\n",
      "1901-03-01    183.1\n",
      "1901-04-01    119.3\n",
      "1901-05-01    180.3\n",
      "Name: Sales of shampoo over a three year period, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:171: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  % freq, ValueWarning)\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:191: FutureWarning: Creating a DatetimeIndex by passing range endpoints is deprecated.  Use `pandas.date_range` instead.\n",
      "  start=index[0], end=index[-1], freq=freq)\n",
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:171: ValueWarning: No frequency information was provided, so inferred frequency MS will be used.\n",
      "  % freq, ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          ARIMA Model Results                                          \n",
      "=======================================================================================================\n",
      "Dep. Variable:     D.Sales of shampoo over a three year period   No. Observations:                   35\n",
      "Model:                                          ARIMA(5, 1, 0)   Log Likelihood                -196.170\n",
      "Method:                                                css-mle   S.D. of innovations             64.241\n",
      "Date:                                         Tue, 18 Jun 2019   AIC                            406.340\n",
      "Time:                                                 16:21:28   BIC                            417.227\n",
      "Sample:                                             02-01-1901   HQIC                           410.098\n",
      "                                                  - 12-01-1903                                         \n",
      "=====================================================================================================================\n",
      "                                                        coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "const                                                12.0649      3.652      3.304      0.003       4.908      19.222\n",
      "ar.L1.D.Sales of shampoo over a three year period    -1.1082      0.183     -6.063      0.000      -1.466      -0.750\n",
      "ar.L2.D.Sales of shampoo over a three year period    -0.6203      0.282     -2.203      0.036      -1.172      -0.068\n",
      "ar.L3.D.Sales of shampoo over a three year period    -0.3606      0.295     -1.222      0.231      -0.939       0.218\n",
      "ar.L4.D.Sales of shampoo over a three year period    -0.1252      0.280     -0.447      0.658      -0.674       0.424\n",
      "ar.L5.D.Sales of shampoo over a three year period     0.1289      0.191      0.673      0.506      -0.246       0.504\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                  Real          Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1           -1.0617           -0.5064j            1.1763           -0.4292\n",
      "AR.2           -1.0617           +0.5064j            1.1763            0.4292\n",
      "AR.3            0.0816           -1.3804j            1.3828           -0.2406\n",
      "AR.4            0.0816           +1.3804j            1.3828            0.2406\n",
      "AR.5            2.9315           -0.0000j            2.9315           -0.0000\n",
      "-----------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "count   35.000000\n",
      "mean    -5.495260\n",
      "std     68.132879\n",
      "min   -133.296631\n",
      "25%    -42.477918\n",
      "50%     -7.186747\n",
      "75%     24.748260\n",
      "max    133.237906\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "def parser(x):\n",
    "    return datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "series = read_csv('shampoo.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# fit model\n",
    "print(series.head())\n",
    "\n",
    "\n",
    "model = ARIMA(series, order=(5,1,0))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())\n",
    "# plot residual errors\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "curr_dir = os.getcwd()\n",
    "dataset = pd.read_csv(\"\\\\Users\\\\ASUS\\\\Documents\\\\IST\\\\5ºAno\\\\CT15Mn-150818_101018\\\\dados_camara.csv\")#dados mais recentes\n",
    "#tomtom = pd.read_csv(\"\\\\Users\\\\ASUS\\\\Documents\\\\IST\\\\5ºAno\\\\tomtom_data.csv\")\n",
    "#dataset = pd.read_csv(\"\\\\Users\\\\ASUS\\\\Documents\\\\IST\\\\5ºAno\\\\periodic_data.csv\") #dados periodicos gerados automaticamente\n",
    "#dataset = pd.read_csv(\"\\\\Users\\\\ASUS\\\\Documents\\\\IST\\\\5ºAno\\\\dados_old.csv\") #dados mais antigos\n",
    "dataset['unique_id'] = dataset.Zona.astype(str) + '_' + dataset.ID_Espira.astype(str)\n",
    "dataset['unique_id'] = dataset['unique_id'].str.lower()\n",
    "dataset = dataset[dataset[\"unique_id\"] == \"4_ct4\"]\n",
    "dataset = dataset.drop(columns=[\"unique_id\"])\n",
    "\n",
    "dataset['Data'] = pd.to_datetime(dataset['Data'], infer_datetime_format=True)\n",
    "#print(dataset[\"Data\"])\n",
    "\n",
    "############# SHOULD BE INPUT FROM USER ###############\n",
    "\n",
    "start_date = np.datetime64('2018-08-20')\n",
    "end_date = np.datetime64('2018-08-24')\n",
    "\n",
    "#######################################################\n",
    "\n",
    "test = dataset[(dataset[\"Data\"]>=start_date) & (dataset[\"Data\"]<=end_date)]\n",
    "#print(test.head())\n",
    "test = test.values\n",
    "\n",
    "############## GETTING ALL THE TIME INTERVALS BETWEEN THE SELECTED DATES ########################\n",
    "start_time = datetime.strptime('2018-08-20', '%Y-%m-%d')\n",
    "end_time = datetime.strptime('2018-08-25', '%Y-%m-%d')\n",
    "def datetime_range(start, end, delta):\n",
    "    current = start\n",
    "    while current < end:\n",
    "        yield current\n",
    "        current += delta\n",
    "hours = [dt.strftime('%Y-%m-%d %H:%M:%S') for dt in datetime_range(start_time,end_time, timedelta(minutes=15))]\n",
    "\n",
    "############# CREATING DATASET ########################\n",
    "def create_data(filename,dataset, hours):    \n",
    "    #o = open(\"arima_sem_data.csv\", \"w\", newline='')\n",
    "    #f = open(\"arima_data.csv\",\"w\", newline='')\n",
    "    f = open(str(filename)+\".csv\",\"w\", newline='')\n",
    "    out_file =  csv.writer(f, delimiter=',',quoting=csv.QUOTE_ALL) #csv.QUOTE_ALL)\n",
    "    out_file.writerow([\"Date/Step\", \"Count\"])\n",
    "\n",
    "    #new_file =  csv.writer(o, delimiter=',',quoting=csv.QUOTE_ALL) #csv.QUOTE_ALL)\n",
    "    #new_file.writerow([\"Date/Step\", \"Count\"])\n",
    "\n",
    "    lazy_hack = 0 \n",
    "    lol = 0\n",
    "    for row in range(len(dataset)):\n",
    "        step = 1\n",
    "        curr_values = dataset[row][4:]\n",
    "        for value in range(len(curr_values)):\n",
    "            out_file.writerow([hours[lazy_hack],curr_values[value]])\n",
    "            lazy_hack+=1\n",
    "            #new_file.writerow([lazy_hack, curr_values[value]])\n",
    "            lol+=1\n",
    "            f.flush()\n",
    "            #o.flush()\n",
    "    f.close()\n",
    "    #o.close()\n",
    "create_data(\"arima_data\", test, hours)\n",
    "#create_data(\"arima_sem_data\", test, hours)\n",
    "\n",
    "########################################################\n",
    "\n",
    "\n",
    "######## TEST SET FIXME!!!! ####################################\n",
    "test_date = np.datetime64('2018-08-27')\n",
    "#end_test_date = np.datetime64('2018-08-28')\n",
    "start_time = datetime.strptime('2018-08-27', '%Y-%m-%d')\n",
    "end_time = datetime.strptime('2018-08-28', '%Y-%m-%d')\n",
    "test_set = dataset[(dataset[\"Data\"]==test_date)] # & (dataset[\"Data\"]<=end_date)]\n",
    "test_set = test_set.values\n",
    "\n",
    "hours_set = [dt.strftime('%Y-%m-%d %H:%M:%S') for dt in datetime_range(start_time,end_time, timedelta(minutes=15))]\n",
    "create_data(\"test_data\", test_set, hours_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date/Step\n",
      "2018-08-20 00:00:00    28\n",
      "2018-08-20 00:15:00    27\n",
      "2018-08-20 00:30:00    26\n",
      "2018-08-20 00:45:00    18\n",
      "2018-08-20 01:00:00    20\n",
      "Name: Count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\IPython\\core\\display.py:689: UserWarning:\n",
      "\n",
      "Consider using IPython.display.IFrame instead\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vasco_leal/6.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as ply\n",
    "import cufflinks as cf\n",
    "########### READING DATASET #####################\n",
    "arima_data2 = pd.read_csv(\"\\\\Users\\\\ASUS\\\\Documents\\\\IST\\\\5ºAno\\\\arima_sem_data.csv\")#dados mais recentes\n",
    "#print(arima_data.head())\n",
    "def parsers(x):\n",
    "    return datetime.strptime(x,'%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "arima_data = read_csv(\"\\\\Users\\\\ASUS\\\\Documents\\\\IST\\\\5ºAno\\\\arima_data.csv\",header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parsers)\n",
    "\n",
    "print(arima_data.head())\n",
    "arima_data2.iplot(title=\"Traffic flow over a period of 5 days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyramid'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-87e9a2127a5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_mpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseasonal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseasonal_decompose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyramid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marima\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauto_arima\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#arima_data[\"Count\"] = pd.to_numeric(arima_data[\"Count\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#print(arima_data[\"Date/Step\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyramid'"
     ]
    }
   ],
   "source": [
    "########## EXPERIMENTING WITH ARIMA #############\n",
    "from plotly.plotly import plot_mpl\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pyramid.arima import auto_arima\n",
    "#arima_data[\"Count\"] = pd.to_numeric(arima_data[\"Count\"])\n",
    "#print(arima_data[\"Date/Step\"])\n",
    "#x = arima_data.values\n",
    "#print(x[:,0,None])\n",
    "#arima_data.index = x[:,0]\n",
    "#arima_data.index = pd.to_datetime(arima_data.index)\n",
    "#print(arima_data.head())\n",
    "#sys.exit()\n",
    "result = seasonal_decompose(arima_data, model='multiplicative',freq=5)\n",
    "fig = result.plot()\n",
    "fig.show()\n",
    "\n",
    "\n",
    "############### FINDING THE BEST PARAMETERS FOR P,Q,D\n",
    "\n",
    "\n",
    "stepwise_model = auto_arima(data, start_p=1, start_q=1,\n",
    "                           max_p=3, max_q=3, m=12,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True)\n",
    "print(stepwise_model.aic())\n",
    "\n",
    "sys.exit()\n",
    "\n",
    "\n",
    "\n",
    "model = ARIMA(arima_data, order=(5,1,0))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe())\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
