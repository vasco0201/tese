{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados estatisticos sobre os dados das espiras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "#threshold = 350\n",
    "espiras_cont = {} #nr de registos de cada espira, soma das contagens por hora para calcular media e mediana\n",
    "espiras_cont_old = {}\n",
    "n_errors = {} #contar os valores que estão acima do threshold por hora FIXME\n",
    "espiras_geo = []\n",
    "zonas =[]\n",
    "avg_total = []\n",
    "def datetime_range(start, end, delta):\n",
    "    current = start\n",
    "    while current < end:\n",
    "        yield current\n",
    "        current += delta\n",
    "\n",
    "dts = [dt.strftime('%H:%M') for dt in \n",
    "       datetime_range(datetime(2016, 9, 1, 0), datetime(2016, 9, 1, 23, 59), \n",
    "       timedelta(minutes=15))]\n",
    "int_to_hour={}\n",
    "for i in range(len(dts)):\n",
    "    int_to_hour[i] = dts[i]\n",
    "\n",
    "    \n",
    "new_file = open(\"extreme_values.csv\",\"w\")\n",
    "new_file.write(\"id,date,value,hour\\n\")\n",
    "contagens = open(\"/home/vasco/tese/dados_camara_todos.csv\", \"r\") #dados 2018\n",
    "reader = csv.reader(contagens)\n",
    "next(reader, None) #skips the header\n",
    "i = 0\n",
    "for row in reader:\n",
    "    if row[3][2:] == \"\":\n",
    "        continue\n",
    "    #if i==0:\n",
    "    #    for i in row[4:]:\n",
    "    #        avg_total.append([float(i)])\n",
    "    #        i=1\n",
    "    #else:\n",
    "    #    for i in range(len(row[4:])):\n",
    "    #        try:\n",
    "    #            avg_total[i].append(float(row[4:][i]))\n",
    "    #        except:\n",
    "    #            print(row[4:][i])\n",
    "    \n",
    "    if (row[1],row[3][2:]) not in espiras_cont: #o row[3][2:] e para ignorar o ct e manter so o id da espira\n",
    "        espiras_cont[(row[1], row[3][2:])] = row[4:]\n",
    "        espiras_cont[(row[1], row[3][2:])].insert(0,1)\n",
    "    else:\n",
    "        espiras_cont[(row[1],row[3][2:])][1:] = [float(x) + float(y) for x, y in zip(espiras_cont[(row[1],row[3][2:])][1:],row[4:])]\n",
    "        espiras_cont[(row[1],row[3][2:])][0] += 1\n",
    "    for value in range(len(row[4:])):\n",
    "        if float(row[4:][value]) >= 2000:\n",
    "            new_file.write(str(row[1])+\":\"+str(row[3][2:])+ \",\"+ str(row[0]) + \",\" + str(row[4:][value])+ \",\" + str(int_to_hour[value]) +\"\\n\")\n",
    "        \n",
    "new_file.close()\n",
    "contagens.close()\n",
    "#print(espiras_cont)\n",
    "#print(avg_total[1])\n",
    "\n",
    "contagens_old = open(\"/home/vasco/tese/dados_camara_todos.csv\", \"r\") #dados antigos\n",
    "reader_old = csv.reader(contagens_old)\n",
    "next(reader_old, None) #skips the header\n",
    "i = 0\n",
    "for row in reader_old:\n",
    "    \n",
    "    try:\n",
    "        if (row[1],row[3][2:]) not in espiras_cont_old:\n",
    "            espiras_cont_old[(row[1], row[3][2:])] = row[4:]\n",
    "            espiras_cont_old[(row[1], row[3][2:])].insert(0,1)\n",
    "        else:\n",
    "            espiras_cont_old[(row[1],row[3][2:])][1:] = [float(x) + float(y) for x, y in zip(espiras_cont_old[(row[1],row[3][2:])][1:],row[4:])]\n",
    "            espiras_cont_old[(row[1],row[3][2:])][0] += 1\n",
    "        i+=1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "contagens_old.close()\n",
    "\n",
    "espiras = open(\"espiras_geo.csv\",\"r\")\n",
    "reader = csv.reader(espiras)\n",
    "\n",
    "next(reader, None) #skips the header\n",
    "for row in reader:\n",
    "    if (row[1],row[2]) not in espiras_geo:\n",
    "        espiras_geo.append((row[1],row[2]))\n",
    "    if row[1] not in zonas:\n",
    "        zonas.append(row[1])\n",
    "chaves = espiras_cont.keys()\n",
    "chaves_old = espiras_cont_old.keys()\n",
    "espiras.close()\n",
    "#print(chaves)\n",
    "#print(len(espiras_geo))\n",
    "#print(espiras_cont)\n",
    "\n",
    "#if i < 5:\n",
    "#    print(row[1],row[3],row[4])\n",
    "#    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentagem de espiras que retornam dados atualmente\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "174\n",
      "Atualmente 137.3 % de todas as espiras georeferenciadas retornaram dados pelo menos uma vez\n",
      "Nos dados antigos 138.1 % de todas as espiras georeferenciadas (atualmente) retornam dados pelo menos uma vez\n"
     ]
    }
   ],
   "source": [
    "lista = list(chaves_old)\n",
    "myset = set(lista)\n",
    "print(len(myset))\n",
    "print(len(chaves_old))\n",
    "\n",
    "working_ratio = (len(chaves)/len(espiras_geo))*100\n",
    "working_ratio_old = (len(chaves_old)/len(espiras_geo))*100\n",
    "print(\"Atualmente \" + str(round(working_ratio,2)) +\" % de todas as espiras georeferenciadas retornaram dados pelo menos uma vez\")\n",
    "print(\"Nos dados antigos \" + str(round(working_ratio_old,2)) +\" % de todas as espiras georeferenciadas (atualmente) retornam dados pelo menos uma vez\")\n",
    "#print(espiras_geo)\n",
    "#inserir aqui um gráfico eventualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 4, '2': 10, '3': 17, '4': 7, '5': 7, '6': 23, '7': 13, '9': 3, '10': 8, '12': 4, '13': 3, '14': 2, '21': 8, '22': 10, '23': 7}\n",
      "{'1': 5, '2': 11, '3': 22, '4': 12, '5': 11, '6': 24, '7': 14, '9': 4, '10': 9, '12': 8, '13': 13, '14': 14, '21': 8, '22': 10, '23': 8}\n",
      "[1.25, 1.1, 1.2941176470588236, 1.7142857142857142, 1.5714285714285714, 1.0434782608695652, 1.0769230769230769, 1.3333333333333333, 1.125, 2.0, 4.333333333333333, 7.0, 1.0, 1.0, 1.1428571428571428]\n",
      "15\n",
      "15\n",
      "[('1', 4), ('2', 10), ('3', 17), ('4', 7), ('5', 7), ('6', 23), ('7', 13), ('9', 3), ('10', 8), ('12', 4), ('13', 3), ('14', 2), ('21', 8), ('22', 10), ('23', 7)]\n",
      "[('1', 5), ('2', 11), ('3', 22), ('4', 12), ('5', 11), ('6', 24), ('7', 14), ('9', 4), ('10', 9), ('12', 8), ('13', 13), ('14', 14), ('21', 8), ('22', 10), ('23', 8)]\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "nr_espiras_obs = {} #dicionario com o numero de espiras disponiveis por zona em que as chaves são o id da zona\n",
    "nr_espiras_expected = {} #igual mas com os valores expectaveis\n",
    "for i in zonas:\n",
    "    for k in chaves:\n",
    "        if k[0] == i:\n",
    "            if k[0] not in nr_espiras_obs:\n",
    "                nr_espiras_obs[k[0]] = 1\n",
    "            else:\n",
    "                nr_espiras_obs[k[0]] +=1\n",
    "    for j in espiras_geo:\n",
    "        if j[0] == i:\n",
    "            if j[0] not in nr_espiras_expected:\n",
    "                nr_espiras_expected[j[0]] = 1\n",
    "            else:\n",
    "                nr_espiras_expected[j[0]] +=1\n",
    "                \n",
    "        \n",
    "ratio_zona2= [] #lista com a percentagem de espiras a funcionar por zona\n",
    "\n",
    "for i in zonas:\n",
    "    try:\n",
    "        ratio_zona2.append(nr_espiras_obs[str(i)]/nr_espiras_expected[str(i)])\n",
    "    except:\n",
    "        ratio_zona2.append(0)\n",
    "#print(ratio_zona2)\n",
    "#print(list(nr_espiras_expected.keys()))\n",
    "#print(list(nr_espiras_obs.keys()))\n",
    "ratio_zona = {k: nr_espiras_obs[k]/nr_espiras_expected[k] for k in nr_espiras_expected.keys() & nr_espiras_obs}\n",
    "s = list(ratio_zona.items())\n",
    "print(nr_espiras_expected)\n",
    "print(nr_espiras_obs)\n",
    "print(ratio_zona2)\n",
    "#print(list(s))\n",
    "print(len(zonas))\n",
    "print(len(list(nr_espiras_obs.items())))\n",
    "#print(list(nr_espiras_obs.values()))\n",
    "x = list(nr_espiras_expected.items())\n",
    "y = list(nr_espiras_obs.items())\n",
    "print(x)\n",
    "print(y)\n",
    "total=0\n",
    "for i in range(len(x)):\n",
    "    total = total + abs(x[i][1] - y[i][1])\n",
    "print(total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    " \n",
    "# data to plot\n",
    "n_groups = len(zonas)\n",
    "ratio_perc = [i * 100 for i in ratio_zona2]\n",
    "expected = list(nr_espiras_expected.values())\n",
    "\n",
    "obs = list(nr_espiras_obs.values()) \n",
    "#obs.insert(0,0) #hack to insert the missing zones in the observed data\n",
    "#obs.insert(10,0)\n",
    "#obs.insert(len(obs),0)\n",
    " \n",
    "# create plot\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "s1 = plt.subplot(111) #plot with the absolute values\n",
    "#s2 = plt.subplot(122) #ratio of working sensors\n",
    "#fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = s1.bar(zonas, expected, bar_width,\n",
    "alpha=opacity,\n",
    "color='b',\n",
    "label='Expected')\n",
    "\n",
    "rects2 = s1.bar(index + bar_width, obs, bar_width,\n",
    "alpha=opacity,\n",
    "color='r',\n",
    "label='Observed')\n",
    " \n",
    "s1.set_xlabel('Zones',fontsize=24)\n",
    "s1.set_ylabel('Nr of functioning sensors',fontsize=24)\n",
    "s1.set_title('Nr of functioning sensors per zone',fontsize=24)\n",
    "s1.set_xticks(index + bar_width, zonas)\n",
    "s1.legend(loc=2, prop={'size': 24})\n",
    "s1.tick_params(axis='both', which='major', labelsize=24)\n",
    "s1.grid(True)\n",
    "#rects3 = s2.bar(zonas, ratio_perc, bar_width,\n",
    "#alpha=opacity,\n",
    "#color='r',\n",
    "#label='(Observado/Esperado)*100')\n",
    "\n",
    "#s2.set_xlabel('Zonas')\n",
    "#s2.set_ylabel('% de espiras a funcionar')\n",
    "#s2.set_title('% de espiras a funcionar por zona')\n",
    "#s2.set_xticks(index + bar_width, zonas)\n",
    "#s2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('espiras_por_zona.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores médios das contagens por hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "avg_cont = copy.deepcopy(espiras_cont)\n",
    "#print(avg_cont)\n",
    "for k in avg_cont:\n",
    "    for i in range(len(avg_cont[k])):\n",
    "        if i > 0:\n",
    "            avg_cont[k][i] = float(avg_cont[k][i])/float(avg_cont[k][0])\n",
    "#print(avg_cont)\n",
    "\n",
    "#Falta implementar desvio padrão\n",
    "#avg_cont[('3','13')]\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valor médio ao longo do dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High five! You successfully sent some data to your account on plotly. View your plot in your browser at https://plot.ly/~vasco_leal/0 or inside your plot.ly account where it is named 'style-bar'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vasco_leal/0.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.offline as off\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "plotly.tools.set_credentials_file(username='vasco_leal', api_key='30n8NHRdxihdGZgPR2Wz')\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/home/vasco/tese/dados_camara_todos.csv\")\n",
    "\n",
    "df['unique_id'] = df.Zona.astype(str) + '_' + df.ID_Espira.astype(str)\n",
    "df['unique_id'] = df['unique_id'].str.lower()\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "\n",
    "#print(df['unique_id'])\n",
    "\n",
    "\n",
    "avg_df = df.groupby(['unique_id'], as_index =False).mean()\n",
    "std_df = df.groupby(['unique_id']).std().reset_index()\n",
    "#print(avg_df)\n",
    "#print(avg_df.head())\n",
    "#print(std_df.head())\n",
    "pa = std_df[std_df['unique_id'] == \"10_ct1\"]\n",
    "#x = pa.values.tolist()\n",
    "#print(x)\n",
    "data = []\n",
    "for index, row in avg_df.iterrows():\n",
    "    xx = list(avg_df)[2:]\n",
    "    yy = list(row[2:])\n",
    "    pa = std_df[std_df['unique_id'] == row[0]]\n",
    "    list_stdev = pa.values.tolist()\n",
    "    trace = go.Bar(x = xx, y = yy, name = row['unique_id'],  marker=dict(color='rgb(239, 92, 7)'),\n",
    "    error_y=dict(\n",
    "        type='data',\n",
    "        array=list_stdev[0][2:],\n",
    "        visible=True))\n",
    "    data.append(trace)\n",
    "#    (df.groupby(['unique_id', 'org'], as_index=False).mean()\n",
    "#            .groupby('cluster')['time'].mean())\n",
    "    \n",
    "#trace1 = go.Bar(\n",
    "#    x=[1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
    "#       2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012],\n",
    "#    y=[219, 146, 112, 127, 124, 180, 236, 207, 236, 263,\n",
    "#       350, 430, 474, 526, 488, 537, 500, 439],\n",
    "#    name='Rest of world',\n",
    "#    marker=dict(\n",
    "#        color='rgb(55, 83, 109)'\n",
    "#    )\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Média das contagens por espira por hora',\n",
    "    xaxis=dict(\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Numero de carros registados',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1.0,\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)'\n",
    "    ),\n",
    "    barmode='group',\n",
    "    bargap=0.15,\n",
    "    bargroupgap=0.1,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "#off.iplot({'data': data, 'layout': layout}, validate=False)\n",
    "py.iplot(fig, filename='style-bar')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listagem de espiras que não retornam dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~vasco_leal/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<chart_studio.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df2 = pd.read_csv(\"/home/vasco/tese/Espiras/InfoCentral_20180119_1803/dados_camara.csv\")\n",
    "\n",
    "df2['unique_id'] = df2.Zona.astype(str) + '_' + df2.ID_Espira.astype(str)\n",
    "df2['unique_id'] = df2['unique_id'].str.lower()\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple']\n",
    "\n",
    "\n",
    "#print(df['unique_id'])\n",
    "\n",
    "\n",
    "avg_df2 = df2.groupby(['unique_id'], as_index =False).mean()\n",
    "std_df2 = df2.groupby(['unique_id']).std().reset_index()\n",
    "#print(avg_df)\n",
    "#print(avg_df.head())\n",
    "#print(std_df.head())\n",
    "pa = std_df2[std_df2['unique_id'] == \"10_ct1\"]\n",
    "#x = pa.values.tolist()\n",
    "#print(x)\n",
    "data2 = []\n",
    "for index, row in avg_df2.iterrows():\n",
    "    xx = list(avg_df2)[2:]\n",
    "    yy = list(row[2:])\n",
    "    pa = std_df2[std_df2['unique_id'] == row[0]]\n",
    "    list_stdev = pa.values.tolist()\n",
    "    trace = go.Bar(x = xx, y = yy, name = row['unique_id'],  marker=dict(color='rgb(239, 92, 7)'),\n",
    "    error_y=dict(\n",
    "        type='data',\n",
    "        array=list_stdev[0][2:],\n",
    "        visible=True))\n",
    "    data2.append(trace)\n",
    "#    (df.groupby(['unique_id', 'org'], as_index=False).mean()\n",
    "#            .groupby('cluster')['time'].mean())\n",
    "    \n",
    "#trace1 = go.Bar(\n",
    "#    x=[1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003,\n",
    "#       2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012],\n",
    "#    y=[219, 146, 112, 127, 124, 180, 236, 207, 236, 263,\n",
    "#       350, 430, 474, 526, 488, 537, 500, 439],\n",
    "#    name='Rest of world',\n",
    "#    marker=dict(\n",
    "#        color='rgb(55, 83, 109)'\n",
    "#    )\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Média das contagens por espira por hora',\n",
    "    xaxis=dict(\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Numero de carros registados',\n",
    "        titlefont=dict(\n",
    "            size=16,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        ),\n",
    "        tickfont=dict(\n",
    "            size=14,\n",
    "            color='rgb(107, 107, 107)'\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1.0,\n",
    "        bgcolor='rgba(255, 255, 255, 0)',\n",
    "        bordercolor='rgba(255, 255, 255, 0)'\n",
    "    ),\n",
    "    barmode='group',\n",
    "    bargap=0.15,\n",
    "    bargroupgap=0.1,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig2 = go.Figure(data=data2, layout=layout)\n",
    "#off.iplot({'data': data, 'layout': layout}, validate=False)\n",
    "py.iplot(fig2, filename='style-bar2')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(espiras_cont.keys())\n",
    "missing = []\n",
    "new = []\n",
    "#print(espiras_geo)\n",
    "f = open(\"espiras_nao_georeferenciadas.txt\",\"w\")\n",
    "f.write(\"Espiras em falta\\n\")\n",
    "for i in espiras_geo:\n",
    "    if i not in l:\n",
    "        missing.append(\"Zona: \" + i[0] + \" ID: \" + i[1])\n",
    "        f.write(\"Zona: \" + i[0] + \" ID: \" + i[1] + \"\\n\")\n",
    "f.write(\"Espiras nao georreferenciadas\\n\")\n",
    "for i in l:\n",
    "    if i not in espiras_geo:\n",
    "        new.append(\"Zona: \" + i[0] + \" ID: \" + i[1])\n",
    "        f.write(\"Zona: \" + i[0] + \" ID: \" + i[1] + \"\\n\")\n",
    "f.close()\n",
    "\n",
    "#print(missing) #espiras que estão georreferenciadas mas não aparecem nos dados\n",
    "#print(new)  #espiras que não estão georreferenciadas mas aparecem nos dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    unique_id  0h00  0h15  0h30  0h45  1h00  1h15      1h30  1h45      2h00  \\\n",
      "97      3_ct2  0.00   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  0.408248   \n",
      "12    12_ct23  0.25   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   \n",
      "85      2_ct8  0.00   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   \n",
      "125     5_ct3  0.00   0.0   0.0   0.0   0.0   0.0  0.816497   0.0  0.000000   \n",
      "36     14_ct2  0.00   0.0   0.0   0.0   0.0   0.0  0.000000   0.0  0.000000   \n",
      "\n",
      "     ...  22h00  22h15  22h30  22h45  23h00  23h15  23h30  23h45       std  \\\n",
      "97   ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.085052   \n",
      "12   ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.100216   \n",
      "85   ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.113897   \n",
      "125  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.140335   \n",
      "36   ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  0.166667   \n",
      "\n",
      "          avg  \n",
      "97   0.034722  \n",
      "12   0.027344  \n",
      "85   0.054167  \n",
      "125  0.057292  \n",
      "36   0.083333  \n",
      "\n",
      "[5 rows x 99 columns]\n"
     ]
    }
   ],
   "source": [
    "x = std_df\n",
    "x = x.drop(columns = ['Zona'])\n",
    "x['std'] = x.iloc[:,1:].mean(axis=1)\n",
    "x.to_csv(\"std.csv\",index=False)\n",
    "x = x.sort_values(by='std', ascending=True)\n",
    "#x.head(n=15)\n",
    "\n",
    "y = avg_df\n",
    "y = y.drop(columns = ['Zona'])\n",
    "y.head()\n",
    "y['avg'] = y.iloc[:,1:].mean(axis=1)\n",
    "y.to_csv(\"avg.csv\",index=False)\n",
    "#y = y.sort_values(by='avg', ascending=True)\n",
    "y.head(n=15)\n",
    "\n",
    "#for index, row in y.iterrows():\n",
    "#    s = 0\n",
    "#    print(row[-1])\n",
    "#    row = list(row[1:])\n",
    "#    for i in row[:-1]:\n",
    "#        s += float(i)\n",
    "#    s= s/96\n",
    "#    print(s)\n",
    "    \n",
    "#    break\n",
    "x = x.assign(avg=y['avg'])\n",
    "print(x.head())\n",
    "new_df = pd.DataFrame()\n",
    "new_df[\"ID\"] = x[\"unique_id\"]\n",
    "new_df[\"Avg\"] = x[\"avg\"]\n",
    "new_df[\"Std\"] = x[\"std\"]\n",
    "\n",
    "new_df.to_csv(\"avg_std.csv\",index=False)\n",
    "x.to_csv(\"avg_vs_std.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
